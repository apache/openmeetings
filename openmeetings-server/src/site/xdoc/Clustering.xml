<?xml version="1.0" encoding="UTF-8"?>
<!--
   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
 -->
<document xmlns="http://maven.apache.org/XDOC/2.0"
		xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		xsi:schemaLocation="http://maven.apache.org/XDOC/2.0 http://maven.apache.org/xsd/xdoc-2.0.xsd">
	<properties>
		<title>Clustering</title>
		<author email="dev@openmeetings.apache.org">Apache OpenMeetings Team</author>
	</properties>

	<body>
		<section name="Description">
			<p>
				OpenMeetings 2.1 or later is required to use clustering. One database is used for all OpenMeetings
				servers, so all database tables are shared across OM instances. Certain folders should be shared
				between all servers to allow access to the files/recording.</p>
		</section>
		<section name="Configuration">
			<ul>
				<li>
					Multiple OM servers should be set up as described in
					<a href="installation.html" target="_blank">
						<b>Installation</b>
					</a>
				</li>
				<li>All servers should be configured to have same Time zone (To avoid
					Schedulers to drop user sessions as outdated)
				</li>
				<li>All servers should be configured to use the same DB</li>
			</ul>
			<subsection name="Network">
				<p>Multicast should be set up on all servers<br/>
					Here are the steps for *nix like systems <a href="https://blogs.agilefaqs.com/2009/11/08/enabling-multicast-on-your-macos-unix/">Reference article</a>
				</p>
				<ol>
					<li>Check your network interface supports multicast by running the following
						command in a terminal window: <source>ifconfig -a</source>
						When you see <code>MULTICAST</code> against your network interface, it means your
						kernel is compiled with Multicast option and your network interface supports it.
					</li>
					<li>Check if multicast routing is configured:
						<source>netstat -nr</source>
						If you don’t see an IP in the range of <code>224.0.0.0 – 239.255.255.255</code> in the first table,
						it means you need to add your desired mutlicast address to your routes table.
					</li>
					<li>To add the multicast address:
						<source>sudo route add -net 224.0.0.0 netmask 240.0.0.0 dev eth0</source>
						NOTE: ensure <code>eth0</code> corresponds to your network interface name<br/>
						Make sure you run this command on all servers you want to be multicast enabled.
					</li>
					<li>Using netstat check if the multicast IP is visible in your route table (see step 2.)</li>
					<li>
						Using tcpdump and ping check if your server is able to multicast.<br/>
						Run the following command on <b>all</b> the servers. <source>sudo tcpdump -ni eth0 host 224.0.0.0</source>
						Run the following command on <b>any</b> server. <source>ping -t 1 -c 2 224.0.0.0</source>
						Check all servers receiving pings
					</li>
					<li>
						Run <source>sudo route -v delete -net 224.0.0.0 netmask 240.0.0.0</source> to disable multicast
					</li>
				</ol>
			</subsection>
			<subsection name="Database">
				<div>All servers should be configured to use the same database. It can be on the server or on the one node
					of the cluster.<br/>
					<div class="bd-callout bd-callout-danger">NOTE: Db other than H2 should be used</div>
				</div>
				<ul>
					<li>Add users who can connect to the database remotely</li>
					<li>Update <code>/opt/om/webapps/openmeetings/WEB-INF/classes/META-INF/persistence.xml</code>
						set correct server address, login and password. Also uncomment following line:
						<source><![CDATA[<property name="openjpa.RemoteCommitProvider" value="tcp(Addresses=127.0.0.1)" />]]></source>
					</li>
					<li>
						<div class="bd-callout bd-callout-danger">
							IMPORTANT: Please ensure your startup scripts has OpenJPA black/white list definition
						</div>
						<p>Here is an example:</p>
						<code>JAVA_OPTS="-Dopenjpa.serialization.class.blacklist=* -Dopenjpa.serialization.class.whitelist=[B,java.util,org.apache.openjpa,org.apache.openmeetings.db.entity"</code>
					</li>
				</ul>
			</subsection>
			<subsection name="File systems">
				<p>If files and recordings using the same physical folders the files and recordings will be available for
				each node. You can do this using Samba or NFS, for example. For using NFS do the following:</p>
				<ul>
					<li>
						To ease upgrade process set OM data dir to some external folder: for ex. /opt/omdata
					</li>
					<li>Install NFS to the data server. In the file <code>/etc/exports</code> add the following lines:
						<source>
/opt/omdata 10.1.1.2(rw,sync,no_subtree_check,no_root_squash)
						</source>
						Here 10.1.1.2 - is node ip for NFS remote access. Add these lines for all nodes except node with
						folders.
					</li>
					<li>
						Install NFS common tools to other nodes. In the file <code>/etc/fstab</code> do the following:
						<source>
10.1.1.1:/opt/omdata /opt/omdata nfs timeo=50,hard,intr
						</source>
						Here 10.1.1.1 – data server ip. And run the command:
						<source>mount -a</source>
					</li>
				</ul>
			</subsection>
			<subsection name="OM nodes configuration">
				<ol>
					<li>
						<p>In the file <code>/opt/om/webapps/openmeetings/WEB-INF/classes/hazelcast.xml</code>:</p>
						<ul>
							<li>Set <code>instance-name</code> for each server to unique value</li>
							<li>Set <code>server.url</code> for each server to full <strong>public</strong> URL of this server (please NOTE using of numeric IP address might broke HTTPS))</li>
							<li>
								Comment out/delete following blocks:
								<source><![CDATA[
<network>
	<join>
		<auto-detection enabled="false"/>
		<multicast enabled="false"/>
		<tcp-ip enabled="false"/>
		<aws enabled="false"/>
	</join>
</network>
								]]></source>
								<source><![CDATA[
<property name="hazelcast.discovery.enabled">false</property>
								]]></source>
							</li>
							<li>
								Un-comment following block (ensure it contains valip parameters):
								<source><![CDATA[
	<network>
		<join>
			<multicast enabled="true">
				<multicast-group>224.0.0.0</multicast-group>
				<multicast-port>54327</multicast-port>
				<multicast-time-to-live>32</multicast-time-to-live>
				<multicast-timeout-seconds>2</multicast-timeout-seconds>
			</multicast>
		</join>
		<interfaces enabled="true">
			<interface>192.168.1.*</interface>
		</interfaces>
	</network>
								]]></source>
							</li>
							<li>
								In case there are more than one network interface with multicast support and/or additional hazelcast configuration is required
								Based on the following documentation: <a href="https://docs.hazelcast.org/docs/4.0/manual/html-single/index.html">https://docs.hazelcast.org/docs/4.0/manual/html-single/index.html</a>
							</li>
						</ul>
					</li>
				</ol>
			</subsection>
			<subsection name="Ensure everything works as expected">
				<ul>
					<li>Set up the cluster and login with two users, go to the same room (also check before room
						entering that the status page with the room list shows the correct number of participants before
						entering the room). You should login to the same server initially, the server will redirect you
						for the conference room to the appropriate server automatically. Both users should be in the same room.
					</li>
					<li>Do the same with only two users but go to _different_ rooms. The calculation should send
						both users to different servers, cause based on the calculation two different rooms on a cluster
						with two nodes should go exactly one room for each node. You can now login really to node1
						and node2 of your cluster while those users are loggedin and go to <code>Administration &gt; Connections</code>
						and check in the column "Server Name" where they are located. They should be on different server.
					</li>
				</ul>
				<img src="images/cluster2.png" alt="" width="650" height="369" />
			</subsection>
		</section>
	</body>
</document>
